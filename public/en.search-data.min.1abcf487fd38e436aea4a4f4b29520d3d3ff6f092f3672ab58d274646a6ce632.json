[{"id":0,"href":"/docs/notes/machine-learning/ml-use-cases/","title":"Ml Use Cases","section":"Machine Learning","content":"\rML use cases in the industry\r#\rThere are various use cases for machine learning, one good way to learn how they work in production is reading tech blogs! A lot of tech companies actually host their own tech blogs or write on Medium. These blogs provide great ways to learn how ML is used across the industry.\nRegression problems\r#\rhttps://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d name name name name name\nClassification problems\r#\rname name name name name\nGraph modeling\r#\rhttps://medium.com/walmartglobaltech/retail-graph-walmarts-product-knowledge-graph-6ef7357963bc name name name name name\nExperiment design and platforms\r#\rhttps://shopify.engineering/using-quasi-experiments-counterfactuals name name name name name\nMLOps and production ML design\r#\rMachine Learning in production: the Booking.com approach name name name\nRanking and recommendations\r#\r"},{"id":1,"href":"/docs/hidden/","title":"Hidden","section":"Docs","content":"\rThis page is hidden in menu\r#\rQuondam non pater est dignior ille Eurotas\r#\r"},{"id":2,"href":"/docs/notes/coding-tools/python/resources/","title":"Resources","section":"Python","content":"\rResources\r#\rOnline courses\rProblem Solving with Algorithms and Data Structures using Python Websites\rIntroductory\r#\rGoogle Python Class Think Python: How to Think Like a Computer Scientist Book: Python Crash Course Intermediate/Advanced\r#\rProblem Solving with Algorithms and Data Structures using Python Advanced\r#\rBook: Robust Python Book: Fluent Python\nVideo Tutorials\rLearn Python - Full Course for Beginners [Tutorial] Pandas \u0026amp; Python for Data Analysis by Example – Full Course for Beginners CS50x 2024 - Lecture 6 - Python Intermediate Python Programming Course Algorithms and Data Structures Tutorial - Full Course for Beginners "},{"id":3,"href":"/docs/notes/coding-tools/r/resources/","title":"Resources","section":"R","content":"\rResources\r#\rWebsites\rCode Academy Statistical Inference Course Notes R for Statistical Learning Applied Statistics with R RPubs "},{"id":4,"href":"/docs/notes/coding-tools/sql/resources/","title":"Resources","section":"SQL","content":"\rResources\r#\rBeginner\rsqlbolt w3schools sql zoo Advanced\rmode sql postgres SQL exercises leetcode sql hackerrank sql freecodecamp sql video tutorial "},{"id":5,"href":"/docs/notes/coding-tools/tools/","title":"Tools","section":"Coding \u0026 Tools","content":"\r3rd Level of Menu\r#\rNefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral),\rnorthbridge_services_troubleshooting, personal(\rfirmware_rw.trash_rw_crm.device(interactive_gopher_personal,\rsoftware, -1), megabit, ergonomicsSoftware(cmyk_usb_panel,\rmips_whitelist_duplex, cpa)));\rif (5) {\rmanagementNetwork += dma - boolean;\rkilohertz_token = 2;\rhoneypot_affiliate_ergonomics = fiber;\r}\rmouseNorthbridge = byte(nybble_xmp_modem.horse_subnet(\ranalogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet),\rgateway_ospf), repository.domain_key.mouse(serverData(fileNetwork,\rtrim_duplex_file), cellTapeDirect, token_tooltip_mashup(\rripcordingMashup)));\rmodule_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) +\rcoreLog.joystick(componentUdpLink), windows_expansion_touchscreen);\rbashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling(\rciscNavigationBacklink, table + cleanDriver), indexProtocolIsp);\r"},{"id":6,"href":"/docs/notes/coding-tools/tools/resources/","title":"Resources","section":"Tools","content":"\rLearning Resources\r#\rWebsites\rLearning Git Branching Online courses\rMissing semester of CS "},{"id":7,"href":"/docs/notes/machine-learning/applied-ml/model_pipeline/","title":"Model Pipeline","section":"Machine Learning","content":"\rPipeline\r#\rimport sklearn.linear_model Data\r#\rModel pipeline\r#\rmodel = sklearn.linear_model.LinearRegression() model.fit(X, y) model.predict(X_test) "},{"id":8,"href":"/docs/notes/machine-learning/supervised-models/","title":"Supervised Models","section":"Machine Learning","content":"\r3rd Level of Menu\r#\rNefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral),\rnorthbridge_services_troubleshooting, personal(\rfirmware_rw.trash_rw_crm.device(interactive_gopher_personal,\rsoftware, -1), megabit, ergonomicsSoftware(cmyk_usb_panel,\rmips_whitelist_duplex, cpa)));\rif (5) {\rmanagementNetwork += dma - boolean;\rkilohertz_token = 2;\rhoneypot_affiliate_ergonomics = fiber;\r}\rmouseNorthbridge = byte(nybble_xmp_modem.horse_subnet(\ranalogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet),\rgateway_ospf), repository.domain_key.mouse(serverData(fileNetwork,\rtrim_duplex_file), cellTapeDirect, token_tooltip_mashup(\rripcordingMashup)));\rmodule_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) +\rcoreLog.joystick(componentUdpLink), windows_expansion_touchscreen);\rbashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling(\rciscNavigationBacklink, table + cleanDriver), indexProtocolIsp);\r"},{"id":9,"href":"/docs/notes/machine-learning/supervised-models/knn/","title":"Knn","section":"Supervised Models","content":"\rK-nearnest neighbor\r#\rConcept\r#\rKNN is a special case where no learning is performed. It is a supervised machine learning algorithm. It is also a non-parametric algorithm, meaning it does not have strict requirements for the underlying distribution of the data. It can be used for regression or classification. The data points are grouped together baesd on similarity metric. The prediction is baed on training data only. sklearn implementation of KNeighbors can be found here.\nAlgorithm\r#\rSplit into training and validation set. Normalize data For each validation data point, estimate its distance to all data in training Select first k data points in training closest to the validation data point, using the distance metric Regression uses k-nearest neighbors\u0026rsquo; mean to predict Classification uses majority voting decide the prediction, if there is a tie then tie-breaking mechanism is required Distance calculation methods\r#\rEuclidean straight line distance supports the standard concept of spatial distance this distance is known as the l2-norm Hamming distance number of positions at which corresponding symbols are different for two strings. used for comparision of binary data strings Haversine calculates the distance travelled over the surface of a sphere, such as the Earth Chebychev assumes the distance is equal to the greatest distance along the individual dimensions Minkowski a generalization of the Manhattan and Euclidean distances to arbitrary powers suitable when there\u0026rsquo;s correlation between features, p=1 is just manhattan distance and p=2 is just euclidean Manhattan restricts distance measurements to follow grid lines. this is sometimes referred to as the Taxi cab distance, since taxis must follow streets, which also gives rise to its formal name, manhattan, for the street grid on the island of Manhattan. this distance is also known as the l1-norm Mahalanobis measure of the distance between a point and a distribution, considering the correlations between features. Cosine calculate similiarity between vectors cosine angle of the bectors Jaccard similar to cosine How is K selected\r#\rThis requires testing and identify the use case of the model. It can be found by experimenting with various k values and check the error rate. At a certain point the accuracy improvement will no longer be significant. The rule of thumb is to use k=sqrt(sample size)/2.\nKNN pros and cons\r#\rPro：\nEasy to use, no actual \u0026ldquo;parameter tuning\u0026rdquo; required like other models Can be used for regression/classification Con：\nResource intensive when data scales up Common use cases\r#\rMissing value imputation, this can be added to scikit-learn pipeline Quick fix for anomly detection where data can be imputated Python implementation (sklearn)\r#\rimport numpy as np from sklearn.neighbors import KNeighborsRegressor from sklearn.metrics import mean_squared_error from math import sqrt from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split ( X, y, test_size=0.2, random_state=12345 ) knn_model = KNeighborsRegressor(n_neighbors=3) knn_model.fit(X_train, y_train) train_preds = knn_model.predict(X_train) mse = mean_squared_error(y_train, train_preds) rmse = sqrt(mse) test_preds = knn_model.predict(X_test) mse = mean_squared_error(y_test, test_preds) rmse = sqrt(mse) rmse Python implementation (raw)\r#\rStep 1: Calculate the distance\r#\rimport numpy as np def distance_calculation(point1,point2): \u0026#34;\u0026#34;\u0026#34; Calculates the distance between two points \u0026#34;\u0026#34;\u0026#34; distance = np.sqrt(np.sum((p1-p2)**2)) return distance Step 2: Calculate KNN\r#\rimport numpy as np def distance_calculation(point1,point2): \u0026#34;\u0026#34;\u0026#34; Calculates the distance between two points \u0026#34;\u0026#34;\u0026#34; distance = np.sqrt(np.sum((p1-p2)**2)) return distance "},{"id":10,"href":"/docs/notes/machine-learning/supervised-models/trees/","title":"Trees","section":"Supervised Models","content":"\rTree models\r#\rDecision trees\r#\r• Tree constructed by recursively splitting a data into new groupings based on statistical measure of the data\nDecision Trees\r#\r"},{"id":11,"href":"/docs/notes/mlops/deployment/","title":"Deployment","section":"MLOPs","content":"\r3rd Level of Menu\r#\rNefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral),\rnorthbridge_services_troubleshooting, personal(\rfirmware_rw.trash_rw_crm.device(interactive_gopher_personal,\rsoftware, -1), megabit, ergonomicsSoftware(cmyk_usb_panel,\rmips_whitelist_duplex, cpa)));\rif (5) {\rmanagementNetwork += dma - boolean;\rkilohertz_token = 2;\rhoneypot_affiliate_ergonomics = fiber;\r}\rmouseNorthbridge = byte(nybble_xmp_modem.horse_subnet(\ranalogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet),\rgateway_ospf), repository.domain_key.mouse(serverData(fileNetwork,\rtrim_duplex_file), cellTapeDirect, token_tooltip_mashup(\rripcordingMashup)));\rmodule_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) +\rcoreLog.joystick(componentUdpLink), windows_expansion_touchscreen);\rbashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling(\rciscNavigationBacklink, table + cleanDriver), indexProtocolIsp);\r"},{"id":12,"href":"/docs/notes/mlops/deployment/readings/","title":"Readings","section":"Deployment","content":"\rOverall\r#\rOnline endpoints\r#\rhttps://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints?view=azureml-api-2\u0026tabs=azure-cli https://cloud.google.com/ai-platform/prediction/docs/deploying-models#rest-api https://ubuntu.com/blog/guide-to-ml-model-serving\n"},{"id":13,"href":"/docs/notes/mlops/resources/","title":"Resources","section":"MLOPs","content":"\r3rd Level of Menu\r#\rNefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral),\rnorthbridge_services_troubleshooting, personal(\rfirmware_rw.trash_rw_crm.device(interactive_gopher_personal,\rsoftware, -1), megabit, ergonomicsSoftware(cmyk_usb_panel,\rmips_whitelist_duplex, cpa)));\rif (5) {\rmanagementNetwork += dma - boolean;\rkilohertz_token = 2;\rhoneypot_affiliate_ergonomics = fiber;\r}\rmouseNorthbridge = byte(nybble_xmp_modem.horse_subnet(\ranalogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet),\rgateway_ospf), repository.domain_key.mouse(serverData(fileNetwork,\rtrim_duplex_file), cellTapeDirect, token_tooltip_mashup(\rripcordingMashup)));\rmodule_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) +\rcoreLog.joystick(componentUdpLink), windows_expansion_touchscreen);\rbashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling(\rciscNavigationBacklink, table + cleanDriver), indexProtocolIsp);\r"},{"id":14,"href":"/docs/notes/mlops/resources/blogs/","title":"Blogs","section":"Resources","content":"\rOverall\r#\rRules of Machine Learning\r#\rhttps://developers.google.com/machine-learning/guides/rules-of-ml\n"},{"id":15,"href":"/docs/notes/product/readings/","title":"Readings","section":"Product","content":"\rBlogs to learn product and business insights\r#\r"},{"id":16,"href":"/about/","title":"About \u0026 Contact","section":"Home","content":"This website is a compilation of various topics and resources for learning about data sciencea and machine learning. It also includes some of my personal study notes over the years to help others learn about data science. It will be updated as frequently as possible. Feel free to leave a comment or merge request for suggestions. There is also a blog section where I write about new learnings and industry experiences in data science.\n"}]